{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rODb9vHvIEbp"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:13:55.318523Z",
     "start_time": "2024-12-20T10:13:54.775816Z"
    },
    "id": "U4KmHBd2cdx9"
   },
   "outputs": [],
   "source": [
    "# Add as many imports as you need.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Input, LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNMMoUiUIW3L"
   },
   "source": [
    "# Laboratory Exercise - Run Mode (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rAh_91OIjeS"
   },
   "source": [
    "## Introduction\n",
    "This laboratory assignment's primary objective is to fine-tune a pre-trained language model for binary classification on a dataset consisting of wine reviews. The dataset contains two attributes: **description** and **points**. The description is a brief text describing the wine and the points represent a quality metric ranging from 1 to 100. If some wine has at least 90 points it is considered **exceptional**. Your task involves predicting if some wine is **exceptional** based on its review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBYI-EypaWom"
   },
   "source": [
    "## The Wine Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCm1qm1mZwMr"
   },
   "source": [
    "Load the dataset using the `datasets` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:20:31.057013Z",
     "start_time": "2024-12-20T10:20:29.309792Z"
    },
    "id": "KMOn4fgcZn8s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['description', 'points'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "dataset = load_dataset(\"csv\", data_files=\"wine-reviews.csv\", split='train[:200]')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:20:40.683657Z",
     "start_time": "2024-12-20T10:20:40.672609Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()\n",
    "# df[\"emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:20:43.529877Z",
     "start_time": "2024-12-20T10:20:43.511461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translucent in color, silky in the mouth, this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the palate, this wine is rich and complex, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The producer blends 57% Chardonnay from the Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pure Baga in all its glory, packed with dry an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think of Subsídio as a contribution rather tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Sour-orange juice, yellow-grapefruit flesh, ci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Here's a solid value wine that should pair wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Whiffs of pollen and saffron lend shades of nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>A 100% varietal wine, this offers a depth of e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Passion fruit, lime and feline aromas give the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  points\n",
       "0    Translucent in color, silky in the mouth, this...       0\n",
       "1    On the palate, this wine is rich and complex, ...       1\n",
       "2    The producer blends 57% Chardonnay from the Ma...       1\n",
       "3    Pure Baga in all its glory, packed with dry an...       1\n",
       "4    Think of Subsídio as a contribution rather tha...       0\n",
       "..                                                 ...     ...\n",
       "195  Sour-orange juice, yellow-grapefruit flesh, ci...       1\n",
       "196  Here's a solid value wine that should pair wit...       0\n",
       "197  Whiffs of pollen and saffron lend shades of nu...       0\n",
       "198  A 100% varietal wine, this offers a depth of e...       1\n",
       "199  Passion fruit, lime and feline aromas give the...       0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for row in df['points']:\n",
    "    if row>=90:\n",
    "        l.append(1)\n",
    "    else:\n",
    "        l.append(0)\n",
    "df['points']=l\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZceBEFuiGpI"
   },
   "source": [
    "### Target Extraction\n",
    "Extract the target **exceptional** for each wine review. If some wine has at least 90 points it is considered **exceptional**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:21:47.254939Z",
     "start_time": "2024-12-20T10:21:47.231535Z"
    },
    "id": "Duz8bzcRKSC7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "dataset= dataset.add_column(\"label\", l)\n",
    "dataset= dataset.remove_columns(\"points\")\n",
    "dataset = dataset.rename_column(\"description\", \"text\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tls69_PrbJKW"
   },
   "source": [
    "## Dataset Splitting\n",
    "Partition the dataset into training and testing sets with an 80:20 ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translucent in color, silky in the mouth, this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the palate, this wine is rich and complex, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The producer blends 57% Chardonnay from the Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pure Baga in all its glory, packed with dry an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think of Subsídio as a contribution rather tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Sour-orange juice, yellow-grapefruit flesh, ci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Here's a solid value wine that should pair wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Whiffs of pollen and saffron lend shades of nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>A 100% varietal wine, this offers a depth of e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Passion fruit, lime and feline aromas give the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    Translucent in color, silky in the mouth, this...      0\n",
       "1    On the palate, this wine is rich and complex, ...      1\n",
       "2    The producer blends 57% Chardonnay from the Ma...      1\n",
       "3    Pure Baga in all its glory, packed with dry an...      1\n",
       "4    Think of Subsídio as a contribution rather tha...      0\n",
       "..                                                 ...    ...\n",
       "195  Sour-orange juice, yellow-grapefruit flesh, ci...      1\n",
       "196  Here's a solid value wine that should pair wit...      0\n",
       "197  Whiffs of pollen and saffron lend shades of nu...      0\n",
       "198  A 100% varietal wine, this offers a depth of e...      1\n",
       "199  Passion fruit, lime and feline aromas give the...      0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:22:04.345135Z",
     "start_time": "2024-12-20T10:22:04.263727Z"
    },
    "id": "PjGGGMxebeoB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLnr8v_dWO1i"
   },
   "source": [
    "## Tokenization\n",
    "Tokenize the texts using the `AutoTokenizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:22:39.803648Z",
     "start_time": "2024-12-20T10:22:34.295152Z"
    },
    "id": "esakOh8iWYEN"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenized_texts = tokenizer(dataset[\"train\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIkAR1Hibiwr"
   },
   "source": [
    "## Fine-tuning a Pre-trained Language Model for Classification\n",
    "Fine-tune a pre-trained language model for classification on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:25:19.825066Z",
     "start_time": "2024-12-20T10:25:17.976872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0578c635f44bcaa84b691395d4f2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c41ef5afe451a823dfab8dba6769d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"text\"], truncation=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:25:46.613677Z",
     "start_time": "2024-12-20T10:25:46.603773Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:25:48.129492Z",
     "start_time": "2024-12-20T10:25:48.117464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 160\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWn1pafKbnxH"
   },
   "source": [
    "    #Define the model using the `AutoModelForSequenceClassification` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:31:09.893102Z",
     "start_time": "2024-12-20T10:31:09.836509Z"
    },
    "id": "IXFIrQthbnkb"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"trainer\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,  # batch size for training\n",
    "    per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "    metric_for_best_model=\"f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuQCSxZbYJOq"
   },
   "source": [
    "Define the traning parameters using the `TrainingArguments` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:31:09.690278Z",
     "start_time": "2024-12-20T10:28:14.307235Z"
    },
    "id": "p3sVs-L1YJHu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVvRS4L1YKHp"
   },
   "source": [
    "Define the training using the `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:33:41.830324Z",
     "start_time": "2024-12-20T10:33:37.053687Z"
    },
    "id": "O7cyG3PhYJ_M"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:33:44.973832Z",
     "start_time": "2024-12-20T10:33:44.968414Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:40:32.142531Z",
     "start_time": "2024-12-20T10:40:32.090516Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFZr21HxYkko"
   },
   "source": [
    "Fine-tune (train) the pre-trained lanugage model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:39:08.925314Z",
     "start_time": "2024-12-20T10:39:08.913537Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:39:09.360997Z",
     "start_time": "2024-12-20T10:39:09.316347Z"
    },
    "id": "U9Dz0P11Ykeh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 03:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.634047</td>\n",
       "      <td>0.749373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.550637</td>\n",
       "      <td>0.720635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.524778</td>\n",
       "      <td>0.774859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.5938518524169922, metrics={'train_runtime': 194.0828, 'train_samples_per_second': 2.473, 'train_steps_per_second': 0.309, 'total_flos': 20666551176480.0, 'train_loss': 0.5938518524169922, 'epoch': 3.0})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5247780680656433,\n",
       " 'eval_f1': 0.7748592870544091,\n",
       " 'eval_runtime': 4.5759,\n",
       " 'eval_samples_per_second': 8.741,\n",
       " 'eval_steps_per_second': 1.093,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyXZwAVab8Cp"
   },
   "source": [
    "Use the trained model to make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "EvMfVum6b_9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VxAvDPtcNCh"
   },
   "source": [
    "Assess the performance of the model by using different metrics provided by the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "V4axpktycQhp"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "logits, labels = predictions.predictions, predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        20\n",
      "           1       0.79      0.75      0.77        20\n",
      "\n",
      "    accuracy                           0.78        40\n",
      "   macro avg       0.78      0.78      0.77        40\n",
      "weighted avg       0.78      0.78      0.77        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwnD_qSpIeXG"
   },
   "source": [
    "# Laboratory Exercise - Bonus Task (+ 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5xnEDq3A2h"
   },
   "source": [
    "Implement a simple machine learning pipeline to classify wine reviews as **exceptional** or not. Use TF-IDF vectorization to convert text into numerical features and train a logistic regression. Split the dataset into training and testing sets, fit the pipeline on the training data, and evaluate its performance using metrics such as precision, recall, and F1-score. Analyze the texts to find the most influential words or phrases associated with the **exceptional** wines. Use the coefficients from the logistic regression trained on TF-IDF features to identify the top positive and negative keywords for **exceptional** wines. Present these keywords in a simple table or visualization (e.g., bar chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akxvW5SZ3DoV"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
